# Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection

This repository contains the implementation of the paper **"Standing on the Shoulders of Giants: Reprogramming Visual-Language Model for General Deepfake Detection"**. The project focuses on leveraging large pre-trained Visual-Language Models (VLMs) to generalize deepfake detection across different datasets and manipulation techniques.

The main idea is to **reprogram multimodal models** by adapting their knowledge from natural image-text learning for **deepfake classification**.

## Features
- Utilizes **pre-trained Visual-Language Models (VLMs)** (CLIP) for deepfake detection.
- Reprograms VLMs for a new task using a **few-shot learning approach**.
- Generalizes well across **multiple deepfake datasets**.
- Supports both **image and video-based deepfake detection**.

